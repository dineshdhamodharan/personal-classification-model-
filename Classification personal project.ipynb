{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-51d7ede7641b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c2dacf68db6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m HeartFail = spark.read.csv('file:////home/dineshpsd67163/cloudxlab_jupyter_notebooks/Project Works/heart failier.csv',\n\u001b[0m\u001b[0;32m      2\u001b[0m                        header=True,inferSchema=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "HeartFail = spark.read.csv('file:////home/dineshpsd67163/cloudxlab_jupyter_notebooks/Project Works/heart failier.csv',\n",
    "                       header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HeartFail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e7894afbc579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mHeartFail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'HeartFail' is not defined"
     ]
    }
   ],
   "source": [
    "HeartFail.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|75.0|\n",
      "|55.0|\n",
      "|65.0|\n",
      "|50.0|\n",
      "|65.0|\n",
      "|90.0|\n",
      "|75.0|\n",
      "|60.0|\n",
      "|65.0|\n",
      "|80.0|\n",
      "|75.0|\n",
      "|62.0|\n",
      "|45.0|\n",
      "|50.0|\n",
      "|49.0|\n",
      "|82.0|\n",
      "|87.0|\n",
      "|45.0|\n",
      "|70.0|\n",
      "|48.0|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HeartFail.columns\n",
    "HeartFail.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column anaemia with null values: 0\n",
      "no. of cells in column diabetes with null values: 0\n",
      "no. of cells in column highBP with null values: 0\n",
      "no. of cells in column sex with null values: 0\n",
      "no. of cells in column smoking with null values: 0\n",
      "no. of cells in column age with null values: 0\n",
      "no. of cells in column death_event with null values: 0\n"
     ]
    }
   ],
   "source": [
    "for col in HeartFail.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", HeartFail.filter(HeartFail[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anaemia: integer (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      " |-- highBP: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- smoking: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- death_event: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HeartFail.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+\n",
      "|summary|            anaemia|          diabetes|            highBP|                sex|           smoking|               age|        death_event|\n",
      "+-------+-------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+\n",
      "|  count|               1196|              1196|              1196|               1196|              1196|              1196|               1196|\n",
      "|   mean|  0.431438127090301|0.4180602006688963|0.3511705685618729| 0.6488294314381271|0.3210702341137124|60.833892976588636| 0.3210702341137124|\n",
      "| stddev|0.49548414801930274|0.4934465075234322|0.4775358307256004|0.47753583072560085|0.4670830251520782|11.879868968829989|0.46708302515207845|\n",
      "|    min|                  0|                 0|                 0|                  0|                 0|              40.0|                  0|\n",
      "|    max|                  1|                 1|                 1|                  1|                 1|              95.0|                  1|\n",
      "+-------+-------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# descriptive\n",
    "\n",
    "HeartFail.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector assambly \n",
    "from pyspark.ml.feature import VectorAssembler ,StandardScaler\n",
    "assembler = VectorAssembler(inputCols=[\"anaemia\",\"diabetes\",\"highBP\",\"sex\",\"smoking\",\"age\"], \n",
    "                            outputCol=\"features\")\n",
    "Heart_feature_vec=assembler.transform(HeartFail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "train_data, test_data = Heart_feature_vec.randomSplit([.8,.2],seed=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(death_event=0, scaledFeatures=DenseVector([-0.8753, -0.8399, -0.739, -1.3547, -0.7036, -1.5902]))]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalling the variables\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(train_data)\n",
    "scaledData = scalerModel.transform(train_data)\n",
    "scaledData_test = scalerModel.transform(test_data)\n",
    "scaledData.select(\"death_event\",\"scaledFeatures\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anaemia: integer (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      " |-- highBP: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- smoking: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- death_event: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaledFeatures: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"death_event\", featuresCol=\"scaledFeatures\", \n",
    "                        maxIter=100, regParam=0.0001, family=\"multinomial\")\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(scaledData)\n",
    "predictions = lrModel.transform(scaledData_test)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"death_event\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6699507389162561\n"
     ]
    }
   ],
   "source": [
    "#acuracy score\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6699507389162562"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5943000854869824"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "evaluator.setMetricName(\"f1\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6394967861752852"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precesion score\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----+\n",
      "|death_event|prediction|count|\n",
      "+-----------+----------+-----+\n",
      "|          0|       0.0|  127|\n",
      "|          1|       0.0|   60|\n",
      "|          0|       1.0|    7|\n",
      "|          1|       1.0|    9|\n",
      "+-----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.createOrReplaceTempView('predictions')\n",
    "spark.sql(\"select death_event, prediction, count(*) as count \\\n",
    "          from predictions \\\n",
    "          group by death_event,prediction \\\n",
    "          order by prediction,death_event\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "lr = LogisticRegression(labelCol=\"death_event\", featuresCol=\"scaledFeatures\")\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"death_event\", predictionCol=\"predictions\", metricName=\"accuracy\")\n",
    "paramgrid = ParamGridBuilder() \\\n",
    "    .baseOn({lr.labelCol: 'death_event'}) \\\n",
    "    .baseOn([lr.predictionCol, 'predictions']) \\\n",
    "    .addGrid(lr.regParam, [1.0, 2.0]) \\\n",
    "    .addGrid(lr.maxIter, [1, 5]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=lr,estimatorParamMaps=paramgrid,evaluator=evaluator,numFolds=3)\n",
    "    \n",
    "cvModel = cv.fit(scaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6600985221674877"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score\n",
    "predicted_df = cvModel.transform (scaledData_test)\n",
    "evaluator.evaluate(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43573005896770123"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precesion score\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "evaluator.evaluate(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6600985221674877"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "evaluator.evaluate(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5249448188156876"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "evaluator.setMetricName(\"f1\")\n",
    "evaluator.evaluate(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|death_event|predictions|count|\n",
      "+-----------+-----------+-----+\n",
      "|          0|        0.0|  134|\n",
      "|          1|        0.0|   69|\n",
      "+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_df.createOrReplaceTempView('predicted_df')\n",
    "spark.sql(\"select death_event, predictions, count(*) as count \\\n",
    "          from predicted_df \\\n",
    "          group by death_event,predictions \\\n",
    "          order by predictions,death_event\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"death_event\", featuresCol=\"scaledFeatures\", \n",
    "                            numTrees=10)\n",
    "rfModel = rf.fit(scaledData)\n",
    "predictions_rf = rfModel.transform(scaledData_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "evaluator = MulticlassClassificationEvaluator(  \n",
    "    labelCol=\"death_event\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_rf)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7390804597701149"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percision score\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241379310344828"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753788710740172"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "evaluator.setMetricName(\"f1\")\n",
    "evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confession matrix before grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----+\n",
      "|death_event|prediction|count|\n",
      "+-----------+----------+-----+\n",
      "|          1|       0.0|   51|\n",
      "|          0|       0.0|  129|\n",
      "|          1|       1.0|   18|\n",
      "|          0|       1.0|    5|\n",
      "+-----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.select('death_event','prediction').groupby('death_event','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"death_event\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "             .addGrid(rf.maxDepth, [2, 6])\\\n",
    "             .addGrid(rf.numTrees, [5, 20])\\\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(scaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7805469749533165"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  accuracy score \n",
    "predictions = cvModel.transform(scaledData)\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046924190934404"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision score\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995971802618328"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall score\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7805469749533165"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "evaluator.setMetricName(\"f1\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confession matrix After grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----+\n",
      "|death_event|prediction|count|\n",
      "+-----------+----------+-----+\n",
      "|          0|       0.0|  129|\n",
      "|          0|       1.0|    5|\n",
      "|          1|       0.0|   51|\n",
      "|          1|       1.0|   18|\n",
      "+-----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.createOrReplaceTempView('rf_predictions')\n",
    "spark.sql(\"select death_event, prediction, count(*) as count \\\n",
    "          from rf_predictions \\\n",
    "          group by death_event,prediction \\\n",
    "          order by death_event,prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel._java_obj.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel._java_obj.getNumTrees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
